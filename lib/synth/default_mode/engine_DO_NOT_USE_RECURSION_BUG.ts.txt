/**
 * Default Mode Audio Engine
 *
 * Main implementation of the Default Mode audio processing system,
 * which combines noise generators, filters, clicks, and effects.
 */

import {
  BoundedSINResolver,
  ResolutionMode,
  SINResolver,
} from "./sin_resolver.ts";
import { HRSResolver } from "./hrs_resolver.ts";
import {
  generateEuclideanRhythm,
  getEuclideanPulseIndices,
} from "./euclidean.ts";
import {
  DEFAULT_MODE_PARAMS,
  getSubdivisionMs,
  parseSubdivision,
} from "./defaults.ts";
import { parseParamId } from "./param_utils.ts";
import {
  ClickParams,
  DefaultModeParamMessage,
  DefaultModeParams,
  FilterParams,
  NoiseParams,
  NoiseType,
  ReverbParams,
  TriggerType,
} from "./types.ts";

/**
 * AudioWorklet processor for click generation
 */
const CLICK_PROCESSOR_CODE = `
class ClickProcessor extends AudioWorkletProcessor {
  static get parameterDescriptors() {
    return [
      { name: 'frequency', defaultValue: 400, minValue: 20, maxValue: 20000 },
      { name: 'duration', defaultValue: 20, minValue: 1, maxValue: 500 },
      { name: 'type', defaultValue: 0, minValue: 0, maxValue: 3 },
      { name: 'attack', defaultValue: 0.001, minValue: 0.001, maxValue: 0.5 },
      { name: 'release', defaultValue: 0.02, minValue: 0.001, maxValue: 0.5 }
    ];
  }

  // Click type constants
  static TYPE_SINE = 0;
  static TYPE_BURST = 1;
  static TYPE_PULSE = 2;
  static TYPE_DIGITAL = 3;

  constructor() {
    super();
    this.isTriggered = false;
    this.triggerTime = 0;
    this.phase = 0;
    
    // For burst noise
    this.noiseBuffer = new Float32Array(1024);
    this.fillNoiseBuffer();
    
    this.port.onmessage = (event) => {
      if (event.data.type === 'trigger') {
        this.triggerClick();
      }
    };
  }
  
  fillNoiseBuffer() {
    for (let i = 0; i < this.noiseBuffer.length; i++) {
      this.noiseBuffer[i] = Math.random() * 2 - 1;
    }
  }
  
  triggerClick() {
    this.isTriggered = true;
    this.triggerTime = 0;
    this.phase = 0;
    this.fillNoiseBuffer(); // Refresh noise for each trigger
  }
  
  process(inputs, outputs, parameters) {
    const output = outputs[0];
    const channel = output[0];
    
    if (!channel || !this.isTriggered) {
      return true;
    }
    
    const type = parameters.type[0] || 0;
    const frequency = parameters.frequency[0] || 400;
    const durationMs = parameters.duration[0] || 20;
    const attack = parameters.attack[0] || 0.001;
    const release = parameters.release[0] || 0.02;
    
    // Convert ms to samples
    const durationSamples = (durationMs / 1000) * sampleRate;
    const attackSamples = attack * sampleRate;
    const releaseSamples = release * sampleRate;
    
    // Generate samples for this buffer
    for (let i = 0; i < channel.length; i++) {
      if (this.isTriggered) {
        let sample = 0;
        
        // Envelope calculation
        let envelope = 1;
        if (this.triggerTime < attackSamples) {
          envelope = this.triggerTime / attackSamples;
        } else if (this.triggerTime > durationSamples - releaseSamples) {
          envelope = (durationSamples - this.triggerTime) / releaseSamples;
          if (envelope < 0) envelope = 0;
        }
        
        // Generate different click types
        switch(Math.round(type)) {
          case ClickProcessor.TYPE_SINE:
            // Sine click
            this.phase += 2 * Math.PI * frequency / sampleRate;
            sample = Math.sin(this.phase);
            break;
            
          case ClickProcessor.TYPE_BURST:
            // Noise burst
            sample = this.noiseBuffer[Math.floor(Math.random() * this.noiseBuffer.length)];
            // Apply bandpass-like filtering to noise
            sample *= Math.sin(this.phase);
            this.phase += 2 * Math.PI * frequency / sampleRate;
            if (this.phase > 2 * Math.PI) this.phase -= 2 * Math.PI;
            break;
            
          case ClickProcessor.TYPE_PULSE:
            // Sharp pulse with decay
            sample = Math.exp(-5 * this.triggerTime / durationSamples);
            if (this.triggerTime < 5) sample = this.triggerTime / 5;
            break;
            
          case ClickProcessor.TYPE_DIGITAL:
            // Digital click (square-like)
            sample = this.triggerTime < durationSamples / 2 ? 1 : -1;
            // Add some harmonics
            sample += 0.2 * Math.sin(2 * Math.PI * frequency * 3 * this.triggerTime / sampleRate);
            break;
            
          default:
            // Fallback: simple decaying sine
            this.phase += 2 * Math.PI * frequency / sampleRate;
            sample = Math.sin(this.phase) * Math.exp(-3 * this.triggerTime / durationSamples);
        }
        
        // Apply envelope and write to output
        channel[i] = sample * envelope;
        
        // Update timing
        this.triggerTime++;
        
        // Check if click is complete
        if (this.triggerTime >= durationSamples) {
          this.isTriggered = false;
        }
      } else {
        channel[i] = 0;
      }
    }
    
    // Copy to other channels if needed
    for (let c = 1; c < output.length; c++) {
      output[c].set(channel);
    }
    
    return true;
  }
}

registerProcessor('click-processor', ClickProcessor);
`;

/**
 * Default Mode Audio Engine
 */
export class DefaultModeEngine {
  /** Web Audio API context */
  private context: AudioContext;

  /** Master output node */
  private outputNode: GainNode;

  /** Master volume control */
  private masterGain: GainNode;

  /** Whether audio worklet module has been loaded */
  private workletLoaded = false;

  /** Current parameter state */
  private params: DefaultModeParams;

  /** Volume check state - starts in volume check mode */
  private isVolumeCheckPending: boolean = true;

  /** Volume check noise source */
  private volumeCheckNoiseSource: AudioBufferSourceNode | null = null;

  /** Volume check gain node */
  private volumeCheckGain: GainNode | null = null;

  /** SIN and HRS resolver instances */
  private resolvers: {
    noiseDensity: SINResolver;
    noiseRate: HRSResolver; // HRS for noise LFO rate
    blipFrequency: SINResolver; // For mid-range tonal pulses
    blipPitchRange: SINResolver; // For mid-range tonal pulses
    clickFrequency: SINResolver; // For high-frequency clicks
    subdivision: HRSResolver;
    pulses: SINResolver;
    rotation: SINResolver;
  };

  /** Clock and timing */
  private timerId: number | null = null;
  private nextTickTime = 0;
  private isPlaying = false;
  private currentStep = 0;
  private patternLength = 16;
  private pulseIndices: number[] = [];

  /** Audio nodes */
  private noiseNodes: {
    source: AudioBufferSourceNode | null;
    gain: GainNode;
    lfo: OscillatorNode | null; // LFO for noise volume
    reverbSend: GainNode; // Control noise to reverb amount
    // Additional LFO-related nodes are created and managed dynamically
  };

  // Filter removed for Ryoji Ikeda aesthetic
  private reverbNode: ConvolverNode | null = null;
  private reverbGain: GainNode;

  // Split click generation into blips (mid-range tonal pulses) and clicks (high-frequency clicks)
  private blipWorklet: AudioWorkletNode | null = null; // For mid-range blips
  private clickWorklet: AudioWorkletNode | null = null; // For high-frequency clicks

  // Envelope removed for Ryoji Ikeda aesthetic

  /** Pre-generated noise buffers */
  private noiseBuffers: Record<NoiseType, AudioBuffer> = {
    white: null as unknown as AudioBuffer,
    pink: null as unknown as AudioBuffer,
    brown: null as unknown as AudioBuffer,
    blue: null as unknown as AudioBuffer,
    violet: null as unknown as AudioBuffer,
  };

  /** Event callbacks */
  private onTrigger: ((type: TriggerType, time: number) => void) | null = null;

  /**
   * Create a new Default Mode audio engine
   * @param context Web Audio API context
   * @param destination Output destination node
   */
  constructor(context: AudioContext, destination: AudioNode) {
    console.log("CONSTRUCTOR CALLED: engine_COMPLEX_BACKUP.ts (Old Complex DefaultModeEngine)");
    
    this.context = context;
    this.params = structuredClone(DEFAULT_MODE_PARAMS);

    // Create resolvers for SIN parameters
    this.resolvers = {
      noiseDensity: new SINResolver(
        this.params.noise.density,
        this.params.noise.densityMode,
      ),
      noiseRate: new HRSResolver(
        this.params.noise.rateNumerator,
        this.params.noise.rateNumeratorMode,
        this.params.noise.rateDenominator,
        this.params.noise.rateDenominatorMode,
      ),
      blipFrequency: new SINResolver(
        this.params.blips.frequency,
        this.params.blips.frequencyMode,
      ),
      blipPitchRange: new SINResolver(
        this.params.blips.pitchRange,
        this.params.blips.pitchRangeMode,
      ),
      clickFrequency: new SINResolver(
        String(this.params.clicks.frequency),
        "static", // Static mode for high-frequency clicks
      ),
      subdivision: new HRSResolver(
        this.params.timing.subdivisionNumerator,
        this.params.timing.subdivisionNumeratorMode,
        this.params.timing.subdivisionDenominator,
        this.params.timing.subdivisionDenominatorMode,
      ),
      pulses: new SINResolver(
        this.params.pattern.pulses,
        this.params.pattern.pulsesMode,
      ),
      rotation: new SINResolver(
        this.params.pattern.rotation,
        this.params.pattern.rotationMode,
      ),
    };

    // Create master gain
    this.masterGain = context.createGain();
    this.masterGain.gain.value = this.params.basic.volume;

    // Create output node (final connection point)
    this.outputNode = context.createGain();
    this.outputNode.connect(destination);

    // Set up audio nodes
    this.noiseNodes = {
      source: null,
      gain: context.createGain(),
      lfo: null,
      reverbSend: context.createGain(),
    };

    // Initialize noise gain (to be controlled by LFO)
    this.noiseNodes.gain.gain.value = 0; // Start silent

    // Initialize noise reverb send (control amount to reverb)
    this.noiseNodes.reverbSend.gain.value = this.params.noise.reverbSend; // Start with no reverb

    // Filter node removed for Ryoji Ikeda aesthetic

    // Envelope removed for Ryoji Ikeda aesthetic

    // Create reverb gain (wet signal)
    this.reverbGain = context.createGain();
    this.reverbGain.gain.value = 0.3; // Initial reverb mix

    // Connect noise directly to master
    this.noiseNodes.gain.connect(this.masterGain);

    // Connect master to output
    this.masterGain.connect(this.outputNode);

    // Initialize noise buffers and reverb impulse response
    this.initializeNoiseBuffers();
    this.initializeReverb();

    // Log audio routing setup for clarity
    console.log("Audio routing setup:");
    console.log(
      "1. Noise has its own path with separate reverb send that defaults to 0",
    );
    console.log(
      "2. Blips and clicks connect to master, which connects to reverb via global mix",
    );

    // Initialize AudioWorklet for clicks
    this.initializeClickProcessor();

    // Set initial pattern
    this.updatePattern();

    // Set up volume check mode if pending
    if (this.isVolumeCheckPending) {
      this.setupVolumeCheck();
    }
  }

  /**
   * Initialize noise buffer generators
   */
  private async initializeNoiseBuffers(): Promise<void> {
    const bufferSize = this.context.sampleRate * 2; // 2 seconds of noise

    // Generate white noise
    const whiteBuffer = this.context.createBuffer(
      1,
      bufferSize,
      this.context.sampleRate,
    );
    const whiteData = whiteBuffer.getChannelData(0);
    for (let i = 0; i < bufferSize; i++) {
      whiteData[i] = Math.random() * 2 - 1;
    }
    this.noiseBuffers.white = whiteBuffer;

    // Generate pink noise (1/f spectrum)
    const pinkBuffer = this.context.createBuffer(
      1,
      bufferSize,
      this.context.sampleRate,
    );
    const pinkData = pinkBuffer.getChannelData(0);
    let b0 = 0, b1 = 0, b2 = 0, b3 = 0, b4 = 0, b5 = 0, b6 = 0;
    for (let i = 0; i < bufferSize; i++) {
      const white = Math.random() * 2 - 1;
      b0 = 0.99886 * b0 + white * 0.0555179;
      b1 = 0.99332 * b1 + white * 0.0750759;
      b2 = 0.96900 * b2 + white * 0.1538520;
      b3 = 0.86650 * b3 + white * 0.3104856;
      b4 = 0.55000 * b4 + white * 0.5329522;
      b5 = -0.7616 * b5 - white * 0.0168980;
      pinkData[i] = (b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362) * 0.11;
      b6 = white * 0.115926;
    }
    this.noiseBuffers.pink = pinkBuffer;

    // Generate brown noise (1/f² spectrum)
    const brownBuffer = this.context.createBuffer(
      1,
      bufferSize,
      this.context.sampleRate,
    );
    const brownData = brownBuffer.getChannelData(0);
    let lastOut = 0;
    for (let i = 0; i < bufferSize; i++) {
      const white = Math.random() * 2 - 1;
      lastOut = (lastOut + (0.02 * white)) / 1.02;
      brownData[i] = lastOut * 3.5; // Normalize
    }
    this.noiseBuffers.brown = brownBuffer;

    // Generate blue noise (high-frequency emphasis)
    const blueBuffer = this.context.createBuffer(
      1,
      bufferSize,
      this.context.sampleRate,
    );
    const blueData = blueBuffer.getChannelData(0);
    let lastBlue = 0;
    for (let i = 0; i < bufferSize; i++) {
      const white = Math.random() * 2 - 1;
      blueData[i] = (white - lastBlue) * 0.5;
      lastBlue = white;
    }
    this.noiseBuffers.blue = blueBuffer;

    // Generate violet noise (1/f with higher frequency emphasis)
    const violetBuffer = this.context.createBuffer(
      1,
      bufferSize,
      this.context.sampleRate,
    );
    const violetData = violetBuffer.getChannelData(0);
    let lastViolet = 0;
    for (let i = 0; i < bufferSize; i++) {
      const white = Math.random() * 2 - 1;
      violetData[i] = white - lastViolet;
      lastViolet = white;
    }
    this.noiseBuffers.violet = violetBuffer;
  }

  /**
   * Static flag to track if reverb has been initialized globally
   * This ensures we only create ONE reverb instance across all engine instances
   */
  private static reverbInitialized = false;

  /**
   * Static reference to the shared reverb node
   * All engine instances will use this same reverb node
   */
  private static sharedReverbNode: ConvolverNode | null = null;

  /**
   * Initialize reverb with impulse response from file
   * Makes sure we use a single shared reverb instance
   */
  private async initializeReverb(): Promise<void> {
    try {
      console.log("Initializing reverb - checking for shared instance");

      // CRITICAL: If we already have a shared reverb node, use it instead of creating a new one
      if (DefaultModeEngine.sharedReverbNode) {
        console.log(
          "Using existing shared reverb node instead of creating a new one",
        );
        this.reverbNode = DefaultModeEngine.sharedReverbNode;
      } else {
        // Create a new reverb node since this is the first time
        console.log("Creating new reverb node (first instance)");
        DefaultModeEngine.sharedReverbNode = this.context.createConvolver();
        this.reverbNode = DefaultModeEngine.sharedReverbNode;

        // This block only runs once across all instances
        try {
          // Load the impulse response from the provided M4A file
          const response = await fetch("/R1NuclearReactorHall.m4a");
          const arrayBuffer = await response.arrayBuffer();
          const audioBuffer = await this.context.decodeAudioData(arrayBuffer);

          // Set the loaded impulse response
          this.reverbNode.buffer = audioBuffer;
          console.log("Loaded impulse response from R1NuclearReactorHall.m4a");
        } catch (fetchErr) {
          console.error("Error loading impulse response file:", fetchErr);

          // Fallback to synthetic impulse response
          console.log("Using synthetic impulse response as fallback");

          // Create impulse response
          const duration = this.params.reverb.decay;
          const decay = this.params.reverb.decay;
          const sampleRate = this.context.sampleRate;
          const length = sampleRate * duration;

          const impulse = this.context.createBuffer(2, length, sampleRate);
          const leftChannel = impulse.getChannelData(0);
          const rightChannel = impulse.getChannelData(1);

          for (let i = 0; i < length; i++) {
            // Exponential decay
            const t = i / sampleRate;
            const gain = Math.exp(-t / decay);

            // Random noise
            const noise = Math.random() * 2 - 1;

            // Apply gain to noise
            leftChannel[i] = noise * gain;

            // Right channel - decorrelate slightly for stereo
            const rightNoise = Math.random() * 2 - 1;
            rightChannel[i] = rightNoise * gain;
          }

          // Set impulse response
          this.reverbNode.buffer = impulse;
        }

        // Mark that we've now initialized the reverb
        DefaultModeEngine.reverbInitialized = true;
      }

      // The rest of the routing configuration happens for every instance

      // Set up dedicated reverb send for noise, which defaults to 0 gain
      // This allows independent control of reverb amount for the noise layer
      this.noiseNodes.gain.connect(this.noiseNodes.reverbSend);
      this.noiseNodes.reverbSend.connect(this.reverbNode);
      console.log(
        `Noise-specific reverb send initialized with gain: ${this.params.noise.reverbSend}`,
      );

      // Connect master gain to reverb for global reverb (affects blips and clicks)
      // This won't affect noise which has its own controlled reverb path
      this.masterGain.connect(this.reverbNode);
      console.log(
        `Global reverb mix initialized with amount: ${this.params.reverb.mix}`,
      );

      // Connect reverb to output through wet gain
      this.reverbNode.connect(this.reverbGain);
      this.reverbGain.connect(this.outputNode);

      // Update reverb params
      this.updateReverbParams(this.params.reverb);
    } catch (err) {
      console.error("Error initializing reverb:", err);
    }
  }

  /**
   * Initialize audio processors for blips and clicks
   */
  private async initializeClickProcessor(): Promise<void> {
    try {
      // Check if AudioWorklet is supported
      if (this.context.audioWorklet) {
        // Create blob URL for the processor
        const blob = new Blob([CLICK_PROCESSOR_CODE], {
          type: "application/javascript",
        });
        const url = URL.createObjectURL(blob);

        // Load the worklet module
        await this.context.audioWorklet.addModule(url);

        // Create the blip worklet node (for mid-range tonal pulses)
        this.blipWorklet = new AudioWorkletNode(
          this.context,
          "click-processor",
        );

        // Connect blips to master gain - this is routed to reverb through master
        this.blipWorklet.connect(this.masterGain);

        // Create the click worklet node (for high-frequency clicks)
        this.clickWorklet = new AudioWorkletNode(
          this.context,
          "click-processor",
        );

        // Connect clicks to master gain - this is routed to reverb through master
        this.clickWorklet.connect(this.masterGain);

        // Mark as loaded
        this.workletLoaded = true;

        // Configure initial parameters for both blips and clicks
        this.updateBlipParams(this.params.blips);
        this.updateClickParams(this.params.clicks);

        // Clean up the URL
        URL.revokeObjectURL(url);
      } else {
        console.warn("AudioWorklet not supported in this browser");
      }
    } catch (err) {
      console.error("Error initializing audio processors:", err);
    }
  }

  /**
   * Set up the volume check mode with continuous pink noise
   */
  private setupVolumeCheck(): void {
    console.log("Setting up volume check mode with pink noise");

    // Ensure context is running
    if (this.context.state === "suspended") {
      this.context.resume();
    }

    // Create gain node for volume check
    this.volumeCheckGain = this.context.createGain();
    this.volumeCheckGain.gain.value = this.params.basic.volumeCheckLevel;

    // Connect to output
    this.volumeCheckGain.connect(this.outputNode);

    // Create and start pink noise source for volume check
    if (this.noiseBuffers && this.noiseBuffers.pink) {
      this.volumeCheckNoiseSource = this.context.createBufferSource();
      this.volumeCheckNoiseSource.buffer = this.noiseBuffers.pink;
      this.volumeCheckNoiseSource.loop = true;

      // Connect to volume check gain
      this.volumeCheckNoiseSource.connect(this.volumeCheckGain);

      // Start the pink noise source
      this.volumeCheckNoiseSource.start();

      console.log(
        `Volume check pink noise started at level: ${this.params.basic.volumeCheckLevel}`,
      );
    } else {
      console.error("Pink noise buffer not available for volume check");
    }
  }

  /**
   * Transition from volume check to full generative mode
   */
  public activateFullGenerativeMode(): void {
    if (!this.isVolumeCheckPending) return; // Already in full generative mode

    console.log("// DEBUG-AUDIO: activateFullGenerativeMode: START");
    console.log(
      `// DEBUG-AUDIO: Pink Noise Gain (at end of volume check): ${this.volumeCheckGain?.gain.value}`,
    );
    console.log(
      `// DEBUG-AUDIO: Master Volume Gain: ${this.masterGain?.gain.value}`,
    );
    console.log(
      `// DEBUG-AUDIO: Reverb Wet Gain: ${this.reverbGain?.gain.value}`,
    );
    console.log(
      `// DEBUG-AUDIO: Noise Layer Current Gain: ${this.noiseNodes.gain.gain.value}`,
    );
    console.log(
      `// DEBUG-AUDIO: Noise Reverb Send Gain: ${this.noiseNodes.reverbSend.gain.value}`,
    );
    console.log(
      `// DEBUG-AUDIO: Basic.Volume param: ${this.params.basic.volume}`,
    );
    console.log(
      `// DEBUG-AUDIO: Noise.Level param: ${this.params.noise.level}`,
    );
    console.log(
      `// DEBUG-AUDIO: Noise.ReverbSend param: ${this.params.noise.reverbSend}`,
    );

    console.log("Activating full generative mode");

    // Update state
    this.isVolumeCheckPending = false;

    // Fade out volume check noise over 500ms
    if (this.volumeCheckGain) {
      const currentTime = this.context.currentTime;
      console.log("// DEBUG-AUDIO: About to transition pink noise control...");
      console.log(
        `// DEBUG-AUDIO: Current Volume Check Gain Value: ${this.volumeCheckGain.gain.value}`,
      );
      console.log(`// DEBUG-AUDIO: Fade Duration: 0.5s`);

      this.volumeCheckGain.gain.setValueAtTime(
        this.volumeCheckGain.gain.value,
        currentTime,
      );
      this.volumeCheckGain.gain.linearRampToValueAtTime(0, currentTime + 0.5);

      // Schedule cleanup of volume check resources
      setTimeout(() => {
        console.log("// DEBUG-AUDIO: Volume check cleanup timeout triggered");

        if (this.volumeCheckNoiseSource) {
          console.log(
            "// DEBUG-AUDIO: Stopping and disconnecting volumeCheckNoiseSource",
          );
          this.volumeCheckNoiseSource.stop();
          this.volumeCheckNoiseSource.disconnect();
          this.volumeCheckNoiseSource = null;
        }

        if (this.volumeCheckGain) {
          console.log("// DEBUG-AUDIO: Disconnecting volumeCheckGain");
          this.volumeCheckGain.disconnect();
          this.volumeCheckGain = null;
        }

        console.log("Volume check resources cleaned up");
      }, 600); // Wait a bit longer than the fade to ensure it completes
    }

    // Start the engine if global on/off is true
    if (this.params.basic.active) {
      console.log(
        "Starting full generative engine automatically because basic.active=true",
      );
      this.start();
    } else {
      console.log(
        "Full generative engine ready but not started (basic.active=false)",
      );
    }
  }

  /**
   * Start audio processing for all enabled layers
   *
   * This starts the pulse scheduler which triggers enabled blips and clicks.
   * The noise layer runs independently based on its own enabled state.
   * This method preserves and reuses the existing audio graph connections.
   */
  public start(): void {
    console.log("// DEBUG-AUDIO: DefaultModeEngine.start() CALLED");
    console.log(`// GLOBAL-ON-OFF DEBUG: DefaultModeEngine.start()`);
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Master Volume Gain: ${this.masterGain?.gain.value}`,
    );
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Basic.Volume param: ${this.params.basic.volume}`,
    );
    console.log(`// GLOBAL-ON-OFF DEBUG: isPlaying state: ${this.isPlaying}`);
    console.log(
      `// GLOBAL-ON-OFF DEBUG: basic.active state: ${this.params.basic.active}`,
    );
    console.log(
      `// GLOBAL-ON-OFF DEBUG: isVolumeCheckPending state: ${this.isVolumeCheckPending}`,
    );

    // Both flags must always be in sync - set them both to true
    this.params.basic.active = true;

    if (this.isPlaying) {
      console.log("// GLOBAL-ON-OFF DEBUG: Already playing, not restarting");
      return;
    }

    // Don't start the generative elements if still in volume check mode
    if (this.isVolumeCheckPending) {
      console.log(
        "// GLOBAL-ON-OFF DEBUG: Start called during volume check - storing basic.active=true for later",
      );
      this.params.basic.active = true;
      return;
    }

    // Start the Web Audio API context if suspended
    if (this.context.state === "suspended") {
      console.log("// GLOBAL-ON-OFF DEBUG: Resuming suspended audio context");
      this.context.resume();
    }

    // Set BOTH flags to true for consistency
    this.isPlaying = true;
    this.params.basic.active = true;
    console.log(
      "// GLOBAL-ON-OFF DEBUG: Set BOTH isPlaying=true AND basic.active=true",
    );

    // Reset timing state for the master clock
    this.nextTickTime = this.context.currentTime;
    this.currentStep = 0;

    // 1. Restore master gain to proper level
    const now = this.context.currentTime;
    this.masterGain.gain.cancelScheduledValues(now);
    this.masterGain.gain.setValueAtTime(0, now); // Start from zero to avoid clicks
    this.masterGain.gain.linearRampToValueAtTime(
      this.params.basic.volume,
      now + 0.05,
    );
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Restored master gain to ${this.params.basic.volume}`,
    );

    // 2. Set up and start noise if it's enabled and not already running
    if (this.params.noise.enabled) {
      if (!this.noiseNodes.source) {
        console.log(
          "// GLOBAL-ON-OFF DEBUG: Setting up noise layer from start()",
        );
        console.log(
          `// GLOBAL-ON-OFF DEBUG: Noise.Level param before setup: ${this.params.noise.level}`,
        );
        console.log(
          `// GLOBAL-ON-OFF DEBUG: Noise Layer Gain before setup: ${this.noiseNodes.gain.gain.value}`,
        );

        this.setupNoise(this.context.currentTime);

        console.log(
          `// GLOBAL-ON-OFF DEBUG: Noise Layer Gain after setup: ${this.noiseNodes.gain.gain.value}`,
        );
      } else {
        // Restore noise gain without recreating source
        console.log(
          "// GLOBAL-ON-OFF DEBUG: Noise source exists, just restoring gain levels",
        );
        this.noiseNodes.gain.gain.cancelScheduledValues(now);
        this.noiseNodes.gain.gain.setValueAtTime(0, now);

        // Set up LFO for the existing noise source
        this.setupNoiseLFO(false); // Don't force reset if LFO exists
      }
    } else {
      console.log("// GLOBAL-ON-OFF DEBUG: Noise layer disabled, not starting");
    }

    // 3. Log status of other layers
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Blip Layer Enabled: ${this.params.blips.enabled}, Level: ${this.params.blips.level}`,
    );
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Click Layer Enabled: ${this.params.clicks.enabled}, Level: ${this.params.clicks.level}`,
    );

    // 4. Start the scheduler for rhythmic events
    this.scheduleNextTick();

    // Emit a custom event for UI/debugging to track engine start
    try {
      const event = new CustomEvent("default-mode-engine-started", {
        detail: {
          timestamp: this.context.currentTime,
          isPlaying: this.isPlaying,
          isActive: this.params.basic.active,
          noiseEnabled: this.params.noise.enabled,
          blipsEnabled: this.params.blips.enabled,
          clicksEnabled: this.params.clicks.enabled,
        },
      });
      globalThis.dispatchEvent(event);
    } catch (_e) {
      // Ignore errors with event dispatch
    }

    console.log(
      `// GLOBAL-ON-OFF DEBUG: Engine started with noise=${this.params.noise.enabled}, blips=${this.params.blips.enabled}, clicks=${this.params.clicks.enabled}`,
    );
  }

  /**
   * Stop the pulse scheduler (affects blips and clicks, and pauses noise LFO)
   *
   * This ONLY stops the master clock and schedulers, and gracefully silences sounds.
   * It does NOT disconnect any audio nodes to ensure easy reactivation.
   */
  public stop(): void {
    console.log("// GLOBAL-ON-OFF DEBUG: Stop method called directly");
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Current isPlaying state: ${this.isPlaying}`,
    );
    console.log(
      `// GLOBAL-ON-OFF DEBUG: Current basic.active state: ${this.params.basic.active}`,
    );
    console.log(`// GLOBAL-ON-OFF DEBUG: Current timerId: ${this.timerId}`);

    // Set BOTH flags to false for consistency - this is critical
    this.isPlaying = false;
    this.params.basic.active = false;
    console.log(
      "// GLOBAL-ON-OFF DEBUG: Set BOTH isPlaying=false AND basic.active=false",
    );

    // 1. Stop master clock/scheduler - ALWAYS attempt to clear timeout to be safe
    if (this.timerId !== null) {
      try {
        globalThis.clearTimeout(this.timerId);
        console.log(
          "// GLOBAL-ON-OFF DEBUG: Successfully cleared timer",
          this.timerId,
        );
      } catch (e) {
        console.log("// GLOBAL-ON-OFF DEBUG: Error clearing timer:", e);
      }
      this.timerId = null;
    } else {
      console.log(
        "// GLOBAL-ON-OFF DEBUG: No active timer to clear (timerId is null)",
      );
    }

    // 2. Gracefully silence audio (without disconnecting nodes)
    try {
      // Gracefully ramp down gains to silence all outputs without disconnecting
      this.silenceGracefully();
      console.log(
        "// GLOBAL-ON-OFF DEBUG: Gracefully silenced audio outputs while preserving connections",
      );
    } catch (e) {
      console.log("// GLOBAL-ON-OFF DEBUG: Error silencing audio:", e);
    }

    // Emit a custom event for UI/debugging to track engine stop
    try {
      const event = new CustomEvent("default-mode-engine-stopped", {
        detail: {
          timestamp: this.context.currentTime,
          isPlaying: this.isPlaying,
          isActive: this.params.basic.active,
        },
      });
      globalThis.dispatchEvent(event);
    } catch (_e) {
      // Ignore errors with event dispatch
    }

    console.log(
      "// GLOBAL-ON-OFF DEBUG: Stop complete - master clock and scheduler stopped, audio silenced gracefully",
    );
  }

  /**
   * Silence all layers gracefully without disconnecting nodes
   *
   * This preserves the audio graph connections but silences all outputs by
   * ramping gain nodes to zero. This allows for easy reactivation.
   */
  private silenceGracefully(): void {
    // Silence all active sounds by ramping gains to zero
    const now = this.context.currentTime;

    // 1. Silence master gain (quick fade out over 50ms)
    const currentMasterGain = this.masterGain.gain.value;
    this.masterGain.gain.cancelScheduledValues(now);
    this.masterGain.gain.setValueAtTime(currentMasterGain, now);
    this.masterGain.gain.linearRampToValueAtTime(0, now + 0.05);
    console.log("Ramped master gain to zero (preserving connections)");

    // 2. Gracefully pause noise LFO (if active)
    if (this.noiseNodes.lfo) {
      // No need to stop LFO, just zero the noise gain
      const currentNoiseGain = this.noiseNodes.gain.gain.value;
      this.noiseNodes.gain.gain.cancelScheduledValues(now);
      this.noiseNodes.gain.gain.setValueAtTime(currentNoiseGain, now);
      this.noiseNodes.gain.gain.linearRampToValueAtTime(0, now + 0.05);
      console.log("Silenced noise (preserving source and connections)");
    }

    // No action needed for blips/clicks - they are triggered per pulse
    // and the master clock is already stopped

    console.log("All layers silenced gracefully with connections preserved");
  }

  /**
   * Hard silence all layers (including stopping sources)
   *
   * This is more destructive than silenceGracefully and should only be used
   * when completely disposing of the engine or when explicitly requested.
   */
  private silenceAll(): void {
    // Cut all active sounds immediately
    const now = this.context.currentTime;

    // Stop noise completely - this will disconnect and null the source
    this.stopNoise(now);

    // No special cleanup needed for blips and clicks as they're triggered per pulse
    console.log("All layers hard silenced (source nodes stopped)");
  }

  /**
   * Hard stop noise generation (stops and removes sources)
   * This is more destructive than just silencing the noise gain.
   * Only use this when completely disposing of the engine.
   */
  private stopNoise(time: number): void {
    console.log("Hard stopping noise layer (stopping sources)");

    // Stop any active noise source
    if (this.noiseNodes.source) {
      this.noiseNodes.source.stop(time);
      // We don't disconnect here - we just stop the node
      // When a source is needed again, setupNoise will handle reconnection
      this.noiseNodes.source = null;
    }

    // Stop any active noise LFO
    if (this.noiseNodes.lfo) {
      this.noiseNodes.lfo.stop(time);
      // We don't disconnect here - we just stop the node
      this.noiseNodes.lfo = null;
    }

    // Ensure noise gain is zeroed immediately
    this.noiseNodes.gain.gain.cancelScheduledValues(time);
    this.noiseNodes.gain.gain.setValueAtTime(0, time);

    // Also zero out reverb send to ensure no residual signal
    if (this.noiseNodes.reverbSend) {
      this.noiseNodes.reverbSend.gain.cancelScheduledValues(time);
      this.noiseNodes.reverbSend.gain.setValueAtTime(0, time);
    }
  }

  /**
   * Start the noise layer if it's enabled
   */
  private startNoise(time: number): void {
    if (!this.params.noise.enabled) return;

    console.log("Starting noise layer");
    this.setupNoise(time);
  }

  /**
   * Schedule the next tick of the master clock
   *
   * HRS RESOLUTION PROCESS:
   * 1. We use the HRSResolver for subdivision, which gives us a numerator and denominator
   * 2. These are already resolved to specific integer values based on their respective
   *    resolution modes (static, random, shuffle, etc.)
   * 3. We pass these values directly to getSubdivisionMs to calculate the duration
   */
  private scheduleNextTick(): void {
    // Double-check that we should still be playing - BOTH flags must be true
    if (!this.isPlaying || !this.params.basic.active) {
      console.log(
        "// GLOBAL-ON-OFF DEBUG: scheduleNextTick called but engine is not playing or not active",
      );
      console.log(
        `// GLOBAL-ON-OFF DEBUG: isPlaying=${this.isPlaying}, basic.active=${this.params.basic.active}`,
      );
      return;
    }

    // Ensure BOTH flags are in sync - if they're not, something is wrong but we'll fix it
    if (this.isPlaying !== this.params.basic.active) {
      console.log(
        `// GLOBAL-ON-OFF DEBUG: FLAG INCONSISTENCY DETECTED in scheduleNextTick!`,
      );
      console.log(
        `// GLOBAL-ON-OFF DEBUG: Setting both flags to the same value`,
      );

      // Sync to the active flag as the source of truth
      this.isPlaying = this.params.basic.active;

      // If both are now false, don't schedule the next tick
      if (!this.isPlaying) {
        console.log(
          `// GLOBAL-ON-OFF DEBUG: Both flags now false, not scheduling next tick`,
        );
        return;
      }
    }

    // Step 1: Get the resolved numerator and denominator from the HRSResolver
    const { numerator, denominator } = this.resolvers.subdivision.next();

    console.log(
      `HRS Resolution: Got numerator=${numerator}, denominator=${denominator}`,
    );

    // Step 2: Now get the actual duration in milliseconds based on CPM
    const subdivisionMs = getSubdivisionMs(
      numerator,
      denominator,
      this.params.basic.tempo, // tempo is in CPM (cycles per minute)
    );

    console.log(
      `HRS Resolution: num=${numerator}, denom=${denominator}, cpm=${this.params.basic.tempo}, ms=${subdivisionMs}`,
    );

    // Set tick time directly from subdivision
    let tickTime = subdivisionMs;

    // Schedule the next tick
    const lookahead = 25; // ms, how far ahead to schedule audio
    const scheduleTime = tickTime - lookahead;

    // Schedule next tick - store the timer ID so we can cancel it if needed
    this.timerId = globalThis.setTimeout(() => {
      // Check again right before ticking to make sure we're still supposed to be playing
      if (this.isPlaying && this.params.basic.active) {
        this.tick();
      } else {
        console.log(
          "// DEBUG-AUDIO: Scheduled tick canceled because engine is no longer playing",
        );
      }
    }, scheduleTime);
  }

  /**
   * Process a tick of the master clock
   */
  private tick(): void {
    console.log("// GLOBAL-ON-OFF DEBUG: tick() method called");
    console.log(
      `// GLOBAL-ON-OFF DEBUG: isPlaying=${this.isPlaying}, basic.active=${this.params.basic.active}`,
    );

    // Emit a custom event for UI/debugging to track master clock ticks
    try {
      // This event can be listened for in the UI to confirm the scheduler is running
      const event = new CustomEvent("default-mode-scheduler-tick", {
        detail: {
          timestamp: this.context.currentTime,
          step: this.currentStep,
        },
      });
      globalThis.dispatchEvent(event);
    } catch (_e) {
      // Ignore errors with event dispatch
    }

    // Double-check that we're still supposed to be playing - BOTH flags must be true
    if (!this.isPlaying || !this.params.basic.active) {
      console.log(
        "// GLOBAL-ON-OFF DEBUG: tick() called but engine is stopped or inactive",
      );
      return;
    }

    // Ensure BOTH flags are in sync - if they're not, something is wrong but we'll fix it
    if (this.isPlaying !== this.params.basic.active) {
      console.log(
        `// GLOBAL-ON-OFF DEBUG: FLAG INCONSISTENCY DETECTED in tick()!`,
      );
      console.log(
        `// GLOBAL-ON-OFF DEBUG: Setting both flags to the same value`,
      );

      // Sync to the active flag as the source of truth
      this.isPlaying = this.params.basic.active;

      // If both are now false, don't process this tick
      if (!this.isPlaying) {
        console.log(
          `// GLOBAL-ON-OFF DEBUG: Both flags now false, not processing tick`,
        );
        return;
      }
    }

    // Time of this tick
    const time = this.nextTickTime;

    // Check if this step is a pulse in the current pattern
    const isPulse = this.pulseIndices.includes(
      this.currentStep % this.patternLength,
    );

    // Generate audio events
    if (isPulse) {
      this.triggerPulse(time);

      // Call trigger callback if set
      if (this.onTrigger) {
        this.onTrigger("pulse", time);
      }
    } else {
      // Regular tick (non-pulse)
      // Call trigger callback if set
      if (this.onTrigger) {
        this.onTrigger("tick", time);
      }
    }

    // Advance to next step
    this.currentStep = (this.currentStep + 1) % 1024; // Large cycle to avoid overflow

    // Calculate next tick time using the HRS resolver
    // Step 1: Get the resolved numerator and denominator from the HRSResolver
    const { numerator, denominator } = this.resolvers.subdivision.next();

    console.log(
      `HRS Resolution (tick): Got numerator=${numerator}, denominator=${denominator}`,
    );

    // Step 2: Get the actual duration in milliseconds based on CPM
    const subdivisionMs = getSubdivisionMs(
      numerator,
      denominator,
      this.params.basic.tempo, // tempo is in CPM (cycles per minute)
    );
    console.log(
      `HRS Resolution (tick): num=${numerator}, denom=${denominator}, cpm=${this.params.basic.tempo}, ms=${subdivisionMs}`,
    );

    this.nextTickTime = time + (subdivisionMs / 1000);

    // Only schedule the next tick if we're still playing
    if (this.isPlaying && this.params.basic.active) {
      this.scheduleNextTick();
    } else {
      console.log(
        "// DEBUG-AUDIO: Not scheduling next tick because engine is no longer playing",
      );
    }
  }

  /**
   * Trigger a pulse event (sound generation)
   * @param time Audio context time to schedule the event
   */
  private triggerPulse(time: number): void {
    // Only trigger if scheduler is running
    if (!this.isPlaying) return;

    // Note: Noise is not triggered with pulses - it runs continuously
    // and is set up once when the engine starts

    // Trigger blips if enabled and worklet is loaded (mid-range tonal pulses)
    if (this.params.blips.enabled && this.blipWorklet) {
      this.triggerBlip(time);
    }

    // Trigger high-frequency clicks if enabled and worklet is loaded
    if (this.params.clicks.enabled && this.clickWorklet) {
      this.triggerClick(time);
    }

    // No envelope in Ryoji Ikeda aesthetic
  }

  /**
   * Configure or update the noise LFO
   * Carefully manages connections to avoid audio glitches
   * @param forceReset Whether to reset the LFO even if already running
   */
  private setupNoiseLFO(forceReset: boolean = false): void {
    console.log("// DEBUG-AUDIO: setupNoiseLFO() CALLED");
    console.log(`// DEBUG-AUDIO: forceReset parameter: ${forceReset}`);

    const time = this.context.currentTime;
    console.log(`// DEBUG-AUDIO: Current audio context time: ${time}`);

    // Calculate LFO frequency based on CPM and HRS ratio
    const { numerator, denominator } = this.resolvers.noiseRate.next();
    console.log(
      `// DEBUG-AUDIO: HRS Resolver result: numerator=${numerator}, denominator=${denominator}`,
    );

    // Calculate LFO rate: CPM frequency * (numerator / denominator)
    // Note: For CPM of 30, denominator of 4 gives a rate of 0.125 Hz (one cycle every 8 seconds)
    const cpmFrequency = this.params.basic.tempo / 60; // Convert CPM to Hz
    const lfoFrequency = cpmFrequency * (numerator / denominator);
    console.log(
      `// DEBUG-AUDIO: CPM Frequency: ${cpmFrequency}Hz from tempo=${this.params.basic.tempo}`,
    );
    console.log(`// DEBUG-AUDIO: Calculated LFO Frequency: ${lfoFrequency}Hz`);

    // Get the maximum volume from noise level parameter
    // Scale down the maximum volume to avoid excessive loudness
    const maxVolume = this.params.noise.level * 0.3; // Reduce by 70% to keep it at a reasonable level
    console.log(
      `// DEBUG-AUDIO: Noise Level param: ${this.params.noise.level}`,
    );
    console.log(
      `// DEBUG-AUDIO: Scaled Maximum Volume (70% reduction): ${maxVolume}`,
    );

    console.log(
      `Noise LFO: rate=${lfoFrequency}Hz (${numerator}/${denominator} of CPM ${this.params.basic.tempo}), maxVolume=${maxVolume}`,
    );

    // Check if we need to create a new LFO
    let needNewLFO = !this.noiseNodes.lfo || forceReset;

    // If we have an existing LFO, try to reuse it
    if (this.noiseNodes.lfo && !forceReset) {
      try {
        // Just a test access to see if the LFO is still valid
        const _dummy = this.noiseNodes.lfo.frequency.value;
        console.log("// DEBUG-AUDIO: Reusing existing LFO - it's still valid");

        // Update the frequency value of the existing LFO
        this.noiseNodes.lfo.frequency.setValueAtTime(lfoFrequency, time);
        console.log(
          `// DEBUG-AUDIO: Updated existing LFO frequency to: ${lfoFrequency}Hz`,
        );

        // We don't need to create a new LFO
        needNewLFO = false;
      } catch (_e) {
        // LFO is invalid or not usable
        console.log(
          "// DEBUG-AUDIO: Existing LFO is invalid, creating new one",
        );
        needNewLFO = true;
      }
    }

    // Only create new LFO components if needed
    if (needNewLFO) {
      console.log("// DEBUG-AUDIO: Creating new LFO setup");

      // Clean up existing LFO if needed (without affecting the rest of the audio graph)
      if (this.noiseNodes.lfo) {
        try {
          // Stop and clean up existing LFO
          console.log("// DEBUG-AUDIO: Cleaning up existing LFO");
          this.noiseNodes.lfo.stop();
          // We don't disconnect here, as that could affect other nodes
          this.noiseNodes.lfo = null;
        } catch (_e) {
          console.log("// DEBUG-AUDIO: Error cleaning up existing LFO:", _e);
        }
      }

      // Create oscillator for LFO
      const lfo = this.context.createOscillator();
      lfo.type = "sine";
      lfo.frequency.value = lfoFrequency;
      console.log(
        `// DEBUG-AUDIO: Created LFO oscillator with frequency: ${lfoFrequency}Hz`,
      );

      // We need a gain node to properly scale the LFO output
      // LFO outputs -1 to 1, but we want 0 to maxVolume
      const lfoScaler = this.context.createGain();

      // Scale the output to go from 0 to maxVolume
      // First, we set the gain to maxVolume/2
      const scalerGainValue = maxVolume / 2;
      lfoScaler.gain.setValueAtTime(scalerGainValue, time);
      console.log(`// DEBUG-AUDIO: Set LFO scaler gain to: ${scalerGainValue}`);

      // Connect LFO to the scaler
      lfo.connect(lfoScaler);
      console.log("// DEBUG-AUDIO: Connected LFO to scaler gain node");

      // Connect scaler to noise gain
      lfoScaler.connect(this.noiseNodes.gain.gain);
      console.log(
        "// DEBUG-AUDIO: Connected LFO scaler to noise gain.gain param",
      );

      // We also need a DC offset to shift the range from -maxVolume/2...maxVolume/2 to 0...maxVolume
      const dcOffset = this.context.createConstantSource();
      const dcOffsetValue = maxVolume / 2;
      dcOffset.offset.setValueAtTime(dcOffsetValue, time);
      console.log(
        `// DEBUG-AUDIO: Created DC offset with value: ${dcOffsetValue}`,
      );

      dcOffset.connect(this.noiseNodes.gain.gain);
      console.log(
        "// DEBUG-AUDIO: Connected DC offset to noise gain.gain param",
      );

      dcOffset.start(time);
      console.log(`// DEBUG-AUDIO: Started DC offset at time: ${time}`);

      // Store references
      this.noiseNodes.lfo = lfo;

      // Always start the LFO if noise is enabled
      lfo.start(time);
      console.log(`// DEBUG-AUDIO: Started noise LFO at time: ${time}`);

      // Check final gain values after setup
      setTimeout(() => {
        console.log(
          `// DEBUG-AUDIO: Noise gain value after 100ms: ${this.noiseNodes.gain.gain.value}`,
        );
      }, 100);
    } else {
      // For existing LFOs that we're reusing, make sure the noise gain is properly set
      // This helps when transitioning from silence back to active state

      // Get current gain value to avoid clicks
      const currentGain = this.noiseNodes.gain.gain.value;

      // Cancel any scheduled values and start a ramp
      this.noiseNodes.gain.gain.cancelScheduledValues(time);
      this.noiseNodes.gain.gain.setValueAtTime(currentGain, time);

      // We don't set a target value here because the LFO will control the gain

      console.log(
        `// DEBUG-AUDIO: Reusing existing LFO, current noise gain: ${currentGain}`,
      );
    }
  }

  /**
   * Start or update continuous noise generation
   * @param time Audio context time to schedule the event
   */
  private setupNoise(time: number): void {
    console.log("// DEBUG-AUDIO: setupNoise() CALLED");
    console.log(`// DEBUG-AUDIO: Time parameter: ${time}`);
    console.log(
      `// DEBUG-AUDIO: Master Volume Gain: ${this.masterGain?.gain.value}`,
    );
    console.log(
      `// DEBUG-AUDIO: Basic.Volume param: ${this.params.basic.volume}`,
    );

    // Always use pink noise (as per Ryoji Ikeda aesthetic)
    const buffer = this.noiseBuffers.pink;

    if (!buffer) {
      console.log("// DEBUG-AUDIO: Pink noise buffer not available, returning");
      return;
    }

    // Ensure WebAudio context is running
    if (this.context.state === "suspended") {
      console.log("// DEBUG-AUDIO: Resuming suspended audio context");
      this.context.resume();
    }

    // Check if we need to create a new noise source
    let needNewSource = !this.noiseNodes.source;

    // If we have an existing source that's playing, keep using it
    if (!needNewSource) {
      try {
        // Just a test access to see if the source is still valid
        const _dummy = this.noiseNodes.source.buffer;
        console.log(
          "// DEBUG-AUDIO: Reusing existing noise source - already properly connected",
        );
      } catch (_e) {
        // If accessing the source throws an error, it's probably ended or invalid
        console.log(
          "// DEBUG-AUDIO: Existing noise source is invalid, creating new one",
        );
        if (this.noiseNodes.source) {
          try {
            this.noiseNodes.source.disconnect();
          } catch (_disconnectErr) {
            // Ignore disconnection errors
          }
        }
        this.noiseNodes.source = null;
        needNewSource = true;
      }
    }

    // Only create a new source if needed
    if (needNewSource) {
      // Create a new noise source
      console.log("// DEBUG-AUDIO: Creating new noise source");
      const source = this.context.createBufferSource();
      source.buffer = buffer;
      source.loop = true;

      // Connect to gain node
      source.connect(this.noiseNodes.gain);

      // Start source
      console.log(`// DEBUG-AUDIO: Starting noise source at time: ${time}`);
      source.start(time);

      // Store reference to current source
      this.noiseNodes.source = source;

      // Only set up routing if this is a new source or connections are missing
      this.ensureNoiseRoutingConnections();
    }

    // Set up the LFO to control the noise volume
    console.log("// DEBUG-AUDIO: Setting up noise LFO");
    this.setupNoiseLFO(needNewSource); // Only force a fresh LFO if we made a new source

    // Restore noise gain to proper level
    this.noiseNodes.gain.gain.cancelScheduledValues(time);
    this.noiseNodes.gain.gain.setValueAtTime(0, time); // Start from 0 to avoid clicks
    // Noise level is managed by the LFO, so we don't set a target value here

    console.log("Continuous pink noise active with LFO modulation");
  }

  /**
   * Ensure noise routing connections are properly established
   * This sets up connections only if they're missing, avoiding unnecessary
   * disconnects and reconnects that could cause issues.
   */
  private ensureNoiseRoutingConnections(): void {
    // We need to check if connections exist before modifying them
    // Unfortunately, Web Audio API doesn't provide a way to check connections directly
    // We'll use a safer approach that only establishes connections we need

    console.log("// DEBUG-AUDIO: Ensuring proper noise routing connections");

    try {
      // Connect noise gain to master gain for the dry signal path
      // This connection is safe to make even if it already exists
      this.noiseNodes.gain.connect(this.masterGain);
      console.log(
        "// DEBUG-AUDIO: Ensured noise gain is connected to master gain",
      );

      // Set up reverb send path if reverb is initialized
      if (this.reverbNode) {
        // These connections are safe to make even if they already exist
        this.noiseNodes.gain.connect(this.noiseNodes.reverbSend);
        this.noiseNodes.reverbSend.connect(this.reverbNode);

        // Set the reverb send amount
        this.noiseNodes.reverbSend.gain.value = this.params.noise.reverbSend;
        console.log(
          `// DEBUG-AUDIO: Ensured reverb routing with send level: ${this.params.noise.reverbSend}`,
        );
      }
    } catch (e) {
      console.log("// DEBUG-AUDIO: Error ensuring noise connections:", e);

      // If we get an error trying to connect, try a complete reconnection
      try {
        // Only use disconnect if we absolutely need to
        this.noiseNodes.gain.disconnect();
        this.noiseNodes.reverbSend.disconnect();

        // Reconnect everything from scratch
        this.noiseNodes.gain.connect(this.masterGain);

        if (this.reverbNode) {
          this.noiseNodes.gain.connect(this.noiseNodes.reverbSend);
          this.noiseNodes.reverbSend.connect(this.reverbNode);
          this.noiseNodes.reverbSend.gain.value = this.params.noise.reverbSend;
        }

        console.log("// DEBUG-AUDIO: Reconnected noise routing after error");
      } catch (reconnectErr) {
        console.error(
          "// DEBUG-AUDIO: Failed to reconnect noise routing:",
          reconnectErr,
        );
      }
    }
  }

  // triggerNoise removed - noise is not triggered with pulses in Ryoji Ikeda aesthetic

  /**
   * Trigger a blip sound (mid-range tonal pulse)
   * @param time Audio context time to schedule the event
   */
  private triggerBlip(time: number): void {
    if (!this.blipWorklet) return;

    // Get random frequency from resolver for blips
    const freqStr = this.resolvers.blipFrequency.next() as string || "440";
    let frequency = parseInt(freqStr, 10);
    if (isNaN(frequency)) frequency = 440;

    // Get pitch range and apply random pitch shift
    const rangeStr = this.resolvers.blipPitchRange.next() as string || "0";
    let pitchRange = parseInt(rangeStr, 10);
    if (isNaN(pitchRange)) pitchRange = 0;

    // Apply random pitch shift within range (semitones)
    if (pitchRange > 0) {
      const semitones = Math.random() * pitchRange;
      frequency *= Math.pow(2, semitones / 12);
    }

    // Set parameters
    const params = this.blipWorklet.parameters;

    // Map blip type to numeric value
    let typeValue = 0;
    switch (this.params.blips.type) {
      case "sine":
        typeValue = 0;
        break;
      case "burst":
        typeValue = 1;
        break;
      case "pulse":
        typeValue = 2;
        break;
      case "digital":
        typeValue = 3;
        break;
    }

    if (params.get("frequency")) {
      params.get("frequency").setValueAtTime(frequency, time);
    }
    if (params.get("duration")) {
      params.get("duration").setValueAtTime(this.params.blips.duration, time);
    }
    if (params.get("type")) params.get("type").setValueAtTime(typeValue, time);

    // Trigger the blip via message
    this.blipWorklet.port.postMessage({ type: "trigger", time });
  }

  /**
   * Trigger a click sound (high-frequency click)
   * @param time Audio context time to schedule the event
   */
  private triggerClick(time: number): void {
    if (!this.clickWorklet) return;

    // High-frequency clicks use fixed frequency
    const frequency = this.params.clicks.frequency;

    // Set parameters
    const params = this.clickWorklet.parameters;

    // High-frequency clicks typically use digital type (type 3)
    let typeValue = 3; // Default to digital click
    if (this.params.clicks.type === "sine") typeValue = 0;
    else if (this.params.clicks.type === "burst") typeValue = 1;
    else if (this.params.clicks.type === "pulse") typeValue = 2;

    if (params.get("frequency")) {
      params.get("frequency").setValueAtTime(frequency, time);
    }
    if (params.get("duration")) {
      params.get("duration").setValueAtTime(this.params.clicks.duration, time);
    }
    if (params.get("type")) params.get("type").setValueAtTime(typeValue, time);

    // Trigger the click via message
    this.clickWorklet.port.postMessage({ type: "trigger", time });
  }

  // Envelope trigger removed for Ryoji Ikeda aesthetic

  /**
   * Update the Euclidean pattern
   */
  private updatePattern(): void {
    // Get pattern parameters
    const steps = this.params.pattern.steps;
    const pulsesStr = this.resolvers.pulses.next() as string || "4";
    const rotationStr = this.resolvers.rotation.next() as string || "0";

    // Parse values
    let pulses = parseInt(pulsesStr, 10);
    if (isNaN(pulses)) pulses = 4;

    let rotation = parseInt(rotationStr, 10);
    if (isNaN(rotation)) rotation = 0;

    // Clamp values
    pulses = Math.max(0, Math.min(pulses, steps));

    // Generate the pattern
    this.patternLength = steps;
    this.pulseIndices = getEuclideanPulseIndices(pulses, steps, rotation);
  }

  // Filter methods removed for Ryoji Ikeda aesthetic

  /**
   * Update blip parameters (mid-range tonal pulses)
   * @param params Blip parameters
   */
  private updateBlipParams(params: BlipParams): void {
    if (!this.blipWorklet) return;

    // Update resolvers for blips
    this.resolvers.blipFrequency.setValues(params.frequency);
    this.resolvers.blipFrequency.setMode(params.frequencyMode);

    this.resolvers.blipPitchRange.setValues(params.pitchRange);
    this.resolvers.blipPitchRange.setMode(params.pitchRangeMode);
  }

  /**
   * Update click parameters (high-frequency clicks)
   * @param params Click parameters
   */
  private updateClickParams(params: ClickParams): void {
    if (!this.clickWorklet) return;

    // Update resolvers for clicks - static frequency for high-frequency clicks
    this.resolvers.clickFrequency.setValues(String(params.frequency));
    this.resolvers.clickFrequency.setMode("static");
  }

  /**
   * Update reverb parameters
   * @param params Reverb parameters
   */
  private updateReverbParams(params: ReverbParams): void {
    console.log("// DEBUG-AUDIO: updateReverbParams() CALLED");

    if (!this.reverbNode || !this.reverbGain) {
      console.log(
        "// DEBUG-AUDIO: Reverb nodes not initialized, returning early",
      );
      return;
    }

    // Set reverb mix (wet/dry)
    console.log(
      `// DEBUG-AUDIO: Previous reverbGain.gain.value: ${this.reverbGain.gain.value}`,
    );
    console.log(`// DEBUG-AUDIO: Setting reverb mix to: ${params.mix}`);
    this.reverbGain.gain.value = params.mix;
    console.log(
      `// DEBUG-AUDIO: New reverbGain.gain.value: ${this.reverbGain.gain.value}`,
    );

    // If decay changes significantly, regenerate impulse response
    const currentDecay = this.reverbNode.buffer?.duration || 0;
    console.log(
      `// DEBUG-AUDIO: Current reverb buffer duration: ${currentDecay}s`,
    );
    console.log(`// DEBUG-AUDIO: New requested decay time: ${params.decay}s`);

    if (Math.abs(currentDecay - params.decay) > 0.5) {
      console.log(
        "// DEBUG-AUDIO: Decay change significant (>0.5s), reinitializing reverb",
      );
      this.initializeReverb();
    } else {
      console.log(
        "// DEBUG-AUDIO: Decay change not significant, skipping reinitialization",
      );
    }
  }

  /**
   * Set a callback function for trigger events
   * @param callback Function to call when a trigger event occurs
   */
  public setTriggerCallback(
    callback: (type: TriggerType, time: number) => void,
  ): void {
    this.onTrigger = callback;
  }

  /**
   * Update a parameter
   * @param message Parameter update message
   */
  public updateParam(message: DefaultModeParamMessage | any): void {
    console.log(
      "// GLOBAL-ON-OFF DEBUG: DefaultModeEngine.updateParam called with message:",
      JSON.stringify(message),
    );

    // Handle both message formats for compatibility
    let group: string, param: string, value: any;

    if (message.type === "default_mode_param") {
      if (message.group && message.param) {
        // Already in the correct format with explicit group and param
        ({ group, param, value } = message);
        console.log(
          `// GLOBAL-ON-OFF DEBUG: Direct format - group=${group}, param=${param}, value=${value}`,
        );
      } else if (message.param) {
        // Format with param as string identifier
        const paramId = message.param;
        value = message.value;

        // Use the parameter utility to parse the parameter ID
        const parsed = parseParamId(paramId);
        group = parsed.group;
        param = parsed.param;
        console.log(
          `// GLOBAL-ON-OFF DEBUG: Parsed from paramId=${paramId} to group=${group}, param=${param}, value=${value}`,
        );
      } else {
        console.warn("Invalid parameter message format:", message);
        return;
      }
    } else {
      // Original format: {group, param, value}
      ({ group, param, value } = message);
      console.log(
        `// GLOBAL-ON-OFF DEBUG: Original format - group=${group}, param=${param}, value=${value}`,
      );
    }

    // Special parameter logging for debugging volume issues
    if (group === "basic" && param === "volume") {
      console.log(
        `// DEBUG-AUDIO: Received defaultGlobalMasterVolume (or mapped equivalent): ${value}`,
      );
      console.log(
        `// DEBUG-AUDIO: Previous masterGain.gain.value: ${this.masterGain.gain.value}`,
      );
    }

    if (group === "reverb" && param === "mix") {
      console.log(
        `// DEBUG-AUDIO: Received defaultGlobalReverbAmount (or mapped equivalent): ${value}`,
      );
      console.log(
        `// DEBUG-AUDIO: Previous reverbGain.gain.value: ${this.reverbGain.gain.value}`,
      );
    }

    if (group === "noise" && param === "reverbSend") {
      console.log(
        `// DEBUG-AUDIO: Received NoiseReverbSend (or mapped equivalent): ${value}`,
      );
      console.log(
        `// DEBUG-AUDIO: Previous noiseNodes.reverbSend.gain.value: ${this.noiseNodes.reverbSend.gain.value}`,
      );
    }

    if (group === "noise" && param === "level") {
      console.log(
        `// DEBUG-AUDIO: Received NoiseLevel (or mapped equivalent): ${value}`,
      );
      console.log(
        `// DEBUG-AUDIO: Previous noise.level: ${this.params.noise.level}`,
      );
      console.log(
        `// DEBUG-AUDIO: Current noiseNodes.gain.gain.value: ${this.noiseNodes.gain.gain.value}`,
      );
    }

    // Update parameter in state
    if (
      group in this.params &&
      param in this.params[group as keyof DefaultModeParams]
    ) {
      const targetGroup = this.params[group as keyof DefaultModeParams];
      const typedValue = value;

      // Update the parameter
      (targetGroup as any)[param] = typedValue;

      // Handle specific parameter updates
      switch (group) {
        case "basic":
          if (param === "volume") {
            console.log(
              `// DEBUG-AUDIO: Setting masterGain.gain.value to: ${value}`,
            );
            this.masterGain.gain.value = value as number;
            console.log(
              `// DEBUG-AUDIO: New masterGain.gain.value: ${this.masterGain.gain.value}`,
            );
          } else if (param === "volumeCheckLevel") {
            // Update volume check level if in volume check mode
            if (this.isVolumeCheckPending && this.volumeCheckGain) {
              console.log(
                `// DEBUG-AUDIO: Setting volumeCheckGain.gain.value to: ${value}`,
              );
              this.volumeCheckGain.gain.value = value as number;
              console.log(
                `// DEBUG-AUDIO: New volumeCheckGain.gain.value: ${this.volumeCheckGain.gain.value}`,
              );
              console.log(`Volume check level updated to ${value}`);
            }
          } else if (param === "active") {
            console.log(
              `// GLOBAL-ON-OFF DEBUG: Processing basic.active parameter`,
            );
            console.log(
              `// GLOBAL-ON-OFF DEBUG: Raw value: ${value}, type: ${typeof value}`,
            );

            // Handle all possible input values consistently
            let isActive: boolean;

            // Convert any value type to a proper boolean
            if (typeof value === "string") {
              // String values - only "true" (case insensitive) is true
              isActive = value.toLowerCase() === "true";
              console.log(
                `// GLOBAL-ON-OFF DEBUG: String value "${value}" -> ${isActive}`,
              );
            } else if (typeof value === "number") {
              // Number values - any non-zero number is true
              isActive = value !== 0;
              console.log(
                `// GLOBAL-ON-OFF DEBUG: Numeric value ${value} -> ${isActive}`,
              );
            } else if (typeof value === "boolean") {
              // Boolean values - direct assignment
              isActive = value;
              console.log(
                `// GLOBAL-ON-OFF DEBUG: Boolean value ${value} -> ${isActive}`,
              );
            } else {
              // Any other type, use standard boolean conversion
              isActive = Boolean(value);
              console.log(
                `// GLOBAL-ON-OFF DEBUG: Other type value ${
                  String(value)
                } -> ${isActive}`,
              );
            }

            // Always ensure both flags stay in sync
            this.params.basic.active = isActive;
            this.isPlaying = isActive;
            console.log(
              `// GLOBAL-ON-OFF DEBUG: Set BOTH params.basic.active AND isPlaying to ${isActive}`,
            );

            // Start or stop the engine based on the boolean value
            if (isActive) {
              console.log(
                `// GLOBAL-ON-OFF DEBUG: Calling this.start() because value resolved to true`,
              );
              this.start();
            } else {
              console.log(
                `// GLOBAL-ON-OFF DEBUG: Calling this.stop() because value resolved to false`,
              );
              this.stop();
            }
          }
          break;

        case "noise":
          // Update noise rate HRS parameters
          if (param === "rateNumeratorMode") {
            console.log(
              `// DEBUG-AUDIO: Setting noiseRate numerator mode to: ${this.params.noise.rateNumeratorMode}`,
            );
            this.resolvers.noiseRate.setNumeratorMode(
              this.params.noise.rateNumeratorMode,
            );
            this.setupNoiseLFO(true); // Force LFO update with new settings
          } else if (param === "rateNumerator") {
            console.log(
              `// DEBUG-AUDIO: Setting noiseRate numerator values to: ${this.params.noise.rateNumerator}`,
            );
            this.resolvers.noiseRate.setNumeratorValues(
              this.params.noise.rateNumerator,
            );
            this.setupNoiseLFO(true); // Force LFO update with new settings
          } else if (param === "rateDenominatorMode") {
            console.log(
              `// DEBUG-AUDIO: Setting noiseRate denominator mode to: ${this.params.noise.rateDenominatorMode}`,
            );
            this.resolvers.noiseRate.setDenominatorMode(
              this.params.noise.rateDenominatorMode,
            );
            this.setupNoiseLFO(true); // Force LFO update with new settings
          } else if (param === "rateDenominator") {
            console.log(
              `// DEBUG-AUDIO: Setting noiseRate denominator values to: ${this.params.noise.rateDenominator}`,
            );
            this.resolvers.noiseRate.setDenominatorValues(
              this.params.noise.rateDenominator,
            );
            this.setupNoiseLFO(true); // Force LFO update with new settings
          } else if (param === "reverbSend") {
            // Update the amount of noise sent to reverb
            if (this.noiseNodes.reverbSend) {
              console.log(
                `// DEBUG-AUDIO: Setting noiseNodes.reverbSend.gain.value to: ${this.params.noise.reverbSend}`,
              );
              this.noiseNodes.reverbSend.gain.value =
                this.params.noise.reverbSend;
              console.log(
                `// DEBUG-AUDIO: New noiseNodes.reverbSend.gain.value: ${this.noiseNodes.reverbSend.gain.value}`,
              );
              console.log(
                `Noise reverb send updated to ${this.params.noise.reverbSend}`,
              );
            }
          } else if (param === "level") {
            // When noise level changes, we need to reinitialize the LFO setup
            // to apply the new maximum volume
            console.log(
              `// DEBUG-AUDIO: Noise level changed to: ${this.params.noise.level}`,
            );
            console.log(
              `// DEBUG-AUDIO: Current noiseNodes.gain.gain.value before LFO reset: ${this.noiseNodes.gain.gain.value}`,
            );

            this.setupNoiseLFO(true); // Force reset with new parameters

            console.log(
              `// DEBUG-AUDIO: New noiseNodes.gain.gain.value after LFO reset: ${this.noiseNodes.gain.gain.value}`,
            );
            console.log(`Noise level updated to ${this.params.noise.level}`);
          } else if (param === "enabled") {
            // Enable/disable noise independent of blips and clicks
            console.log(
              `// DEBUG-AUDIO: Setting noise.enabled to: ${this.params.noise.enabled}`,
            );
            if (this.params.noise.enabled) {
              // Start noise regardless of other layers' state
              console.log(`// DEBUG-AUDIO: About to call startNoise()`);
              this.startNoise(this.context.currentTime);
              console.log("Noise layer enabled");
            } else {
              // Stop noise layer without affecting other layers
              console.log(`// DEBUG-AUDIO: About to call stopNoise()`);
              this.stopNoise(this.context.currentTime);
              console.log("Noise layer disabled");
            }
          }

          // Legacy parameters
          if (param === "densityMode" || param === "density") {
            this.resolvers.noiseDensity.setMode(this.params.noise.densityMode);
            this.resolvers.noiseDensity.setValues(this.params.noise.density);
          }

          break;

        // Filter case removed for Ryoji Ikeda aesthetic

        case "blips":
          if (param === "enabled") {
            // Blips layer can be toggled independently
            console.log(`// DEBUG-AUDIO: Setting blips.enabled to: ${value}`);
            console.log(`Blips layer ${value ? "enabled" : "disabled"}`);
          }
          // Note: reverbSend parameter is in the interface but we're simplifying
          // and using only one global reverb amount and a separate reverb send for noise
          this.updateBlipParams(this.params.blips);
          break;

        case "clicks":
          if (param === "enabled") {
            // Clicks layer can be toggled independently
            console.log(`// DEBUG-AUDIO: Setting clicks.enabled to: ${value}`);
            console.log(`Clicks layer ${value ? "enabled" : "disabled"}`);
          }
          // Note: reverbSend parameter is in the interface but we're simplifying
          // and using only one global reverb amount and a separate reverb send for noise
          this.updateClickParams(this.params.clicks);
          break;

        case "timing":
          if (param === "subdivisionNumeratorMode") {
            this.resolvers.subdivision.setNumeratorMode(
              this.params.timing.subdivisionNumeratorMode,
            );
          } else if (param === "subdivisionNumerator") {
            this.resolvers.subdivision.setNumeratorValues(
              this.params.timing.subdivisionNumerator,
            );
          } else if (param === "subdivisionDenominatorMode") {
            this.resolvers.subdivision.setDenominatorMode(
              this.params.timing.subdivisionDenominatorMode,
            );
          } else if (param === "subdivisionDenominator") {
            this.resolvers.subdivision.setDenominatorValues(
              this.params.timing.subdivisionDenominator,
            );
          }
          break;

        case "pattern":
          if (
            param === "pulsesMode" || param === "pulses" ||
            param === "rotationMode" || param === "rotation" ||
            param === "steps"
          ) {
            if (param === "pulsesMode" || param === "pulses") {
              this.resolvers.pulses.setMode(this.params.pattern.pulsesMode);
              this.resolvers.pulses.setValues(this.params.pattern.pulses);
            }

            if (param === "rotationMode" || param === "rotation") {
              this.resolvers.rotation.setMode(this.params.pattern.rotationMode);
              this.resolvers.rotation.setValues(this.params.pattern.rotation);
            }

            this.updatePattern();
          }
          break;

        case "reverb":
          console.log(
            `// DEBUG-AUDIO: About to update reverb parameters: mix=${this.params.reverb.mix}, decay=${this.params.reverb.decay}`,
          );
          this.updateReverbParams(this.params.reverb);
          break;
      }
    }
  }

  /**
   * Get the current parameter state
   * @returns Copy of current parameters
   */
  public getParams(): DefaultModeParams {
    return structuredClone(this.params);
  }

  /**
   * Get the current volume check state
   * @returns Whether the engine is in volume check pending state
   */
  public getIsVolumeCheckPending(): boolean {
    return this.isVolumeCheckPending;
  }

  /**
   * Manually trigger a sound event
   */
  public manualTrigger(): void {
    if (!this.isPlaying) return;

    const time = this.context.currentTime;
    this.triggerPulse(time);

    // Call trigger callback if set
    if (this.onTrigger) {
      this.onTrigger("manual", time);
    }
  }

  /**
   * Clean up resources - only called when fully disposing of the engine
   */
  public dispose(): void {
    // First stop all processing (scheduler/clock)
    this.stop();

    // Now do a HARD silence of all audio (actual node disconnections)
    // This is only appropriate for full disposal, not for temporary on/off toggling
    this.silenceAll(); // The hard silence version

    // Explicitly disconnect all nodes EXCEPT the shared reverb node
    console.log("Disconnecting all audio nodes for complete disposal");

    this.masterGain.disconnect();
    // Envelope removed for Ryoji Ikeda aesthetic
    // Filter removed for Ryoji Ikeda aesthetic
    if (this.noiseNodes.source) this.noiseNodes.source.disconnect();
    this.noiseNodes.gain.disconnect();
    if (this.noiseNodes.lfo) this.noiseNodes.lfo.disconnect();
    if (this.blipWorklet) this.blipWorklet.disconnect();
    if (this.clickWorklet) this.clickWorklet.disconnect();

    // IMPORTANT: Don't disconnect the shared reverb node, just disconnect our connections to it
    // We can disconnect our reverb gain (wet) node safely
    this.reverbGain.disconnect();

    // Disconnect our output node
    this.outputNode.disconnect();

    console.log(
      "Engine resources fully disposed (shared reverb node preserved)",
    );
  }
}
